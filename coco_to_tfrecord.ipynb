{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note- this is a copied and slightly modified version of Google's tf model gardent code. The original can be found at https://github.com/tensorflow/models/tree/master/official/projects/waste_identification_ml/pre_processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsIv6LYT84gm"
      },
      "source": [
        "# Conversion of COCO annotation JSON file to TFRecords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl7o2xEW9IbX"
      },
      "source": [
        "Given a COCO annotated JSON file, your goal is to convert it into a TFRecords  file necessary to train with the Mask RCNN model.\n",
        "\n",
        "To accomplish this task, you will clone the TensorFlow Model Garden repo. The TensorFlow Model Garden is a repository with a number of different implementations of state-of-the-art (SOTA) models and modeling solutions for TensorFlow users.\n",
        "\n",
        "This notebook is an end to end example. When you run the notebook, it will take COCO annotated JSON train and test files as an input and will convert them into TFRecord files. You can also output sharded TFRecord files in case your training and validation data is huge. It makes it easier for the algorithm to read and access the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3OHfWQBpYVB"
      },
      "source": [
        "**Note** - In this example, we assume that all our data is saved on Google drive and we will also write our outputs to Google drive. We also assume that the script will be used as a Google Colab notebook. But this can be changed according to the needs of users. They can modify this in case they are working on their local workstation, remote server or any other database. This colab notebook can be changed to a regular jupyter notebook running on a local machine according to the need of the users."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRwVTTPuED_1"
      },
      "source": [
        "## Run the below command to connect to your google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnsra7Zf0uGe"
      },
      "outputs": [],
      "source": [
        "!pip install -q tf-nightly\n",
        "!pip install -q tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBN0CZWlD7zl"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "from google.colab import drive\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5HNdeBp0x3G"
      },
      "outputs": [],
      "source": [
        "# \"opencv-python-headless\" version should be same of \"opencv-python\"\n",
        "import pkg_resources\n",
        "version_number = pkg_resources.get_distribution(\"opencv-python\").version\n",
        "\n",
        "!pip install -q opencv-python-headless==$version_number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i80tEP0pEJif"
      },
      "outputs": [],
      "source": [
        "# connect to google drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# making an alias for the root path\n",
        "try:\n",
        "  !ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "  print('Successful')\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "  print('Not successful')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w40-VpWXU-Hu"
      },
      "source": [
        "## Clone TensorFlow Model Garden repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vh42KtozpqeT"
      },
      "outputs": [],
      "source": [
        "# clone the Model Garden directory for Tensorflow where all the config files and scripts are located for this project.\n",
        "# project folder name is - 'waste_identification_ml'\n",
        "!git clone https://github.com/tensorflow/models.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wm-k6-S4pr_B"
      },
      "outputs": [],
      "source": [
        "# Go to the model folder\n",
        "%cd models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNe2NuqjV4uW"
      },
      "source": [
        "## Create TFRecord for training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9Nz75g0oJkI"
      },
      "outputs": [],
      "source": [
        "training_images_folder = '/home/rbe07/Documents/Google/zerowaste-f-final/splits_final_deblurred/train/data/'  #@param {type:\"string\"}\n",
        "training_annotation_file = '/home/rbe07/Documents/Google/zerowaste-f-final/splits_final_deblurred/train/labels_material.json'  #@param {type:\"string\"}\n",
        "output_folder = '/home/rbe07/Documents/Google/zerowaste-f-final/tf_data/train/material/'  #@param {type:\"string\"}\n",
        "training_images_folder = '/home/rbe07/Documents/Google/data/sequences/'\n",
        "training_annotation_file = '/home/rbe07/Downloads/temp.json'\n",
        "output_folder = '/home/rbe07/Documents/Google/data/tf_records/'  #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "os.chdir(\"/home/rbe07/Documents/Google/models\")\n",
        "# sys.path.append('/home/rbe07/Documents/Google/models')\n",
        "\n",
        "# print(sys.path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjsai7PDAxgp"
      },
      "outputs": [],
      "source": [
        "# run the script to convert your json file to TFRecord file\n",
        "# --num_shards (how many TFRecord sharded files you want)\n",
        "\n",
        "# sources = ['a2_oc_0.0', 'a2_oc_50.0', 'a2_oc_90.0', 'a2_oc_99.0']\n",
        "sources = ['hard_50.0', 'hard_90.0', 'hard_99.0']\n",
        "\n",
        "for source in sources:\n",
        "      training_annotation_file = '/home/rbe07/Downloads/'+source+'.json'\n",
        "      output_folder = os.path.join('/home/rbe07/Documents/Google/data', source)+\"/\"  #@param {type:\"string\"}\n",
        "      # training_annotation_file = \"/home/rbe07/Documents/DEVA_rep/Tracking-Anything-with-DEVA/example/output/pred.json\"\n",
        "      os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "      !python3 -m official.vision.data.create_coco_tf_record \\\n",
        "            --logtostderr \\\n",
        "            --image_dir=$training_images_folder \\\n",
        "            --object_annotations_file=$training_annotation_file \\\n",
        "            --output_file_prefix=$output_folder \\\n",
        "            --num_shards=100 \\\n",
        "            --include_masks=True \\\n",
        "            --num_processes=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwazp89SojMA"
      },
      "source": [
        "## Create TFRecord for validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVQn5DiFBUfv"
      },
      "outputs": [],
      "source": [
        "validation_data_folder = '/home/rbe07/Documents/Google/zerowaste-f-final/splits_final_deblurred/val/data/'  #@param {type:\"string\"}\n",
        "validation_annotation_file = '/home/rbe07/Documents/Google/zerowaste-f-final/splits_final_deblurred/val/labels_material.json'  #@param {type:\"string\"}\n",
        "output_folder = '/home/rbe07/Documents/Google/zerowaste-f-final/tf_data/val/material/'  #@param {type:\"string\"}\n",
        "\n",
        "validation_data_folder = '/home/rbe07/Documents/Google/data/sequences/hand_labeled_corrected'\n",
        "validation_annotation_file = '/home/rbe07/Documents/Google/data/sequences/Labels/hand_labeled_corrected_labels.json'\n",
        "output_folder = '/home/rbe07/Documents/Google/data/tf_records_test/'  #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWbKeLoVwXbi"
      },
      "outputs": [],
      "source": [
        "# run the script to convert your json file to TFRecord file\n",
        "# --num_shards (how many TFRecord sharded files you want)\n",
        "!python3 -m official.vision.data.create_coco_tf_record --logtostderr \\\n",
        "      --image_dir=$validation_data_folder \\\n",
        "      --object_annotations_file=$validation_annotation_file \\\n",
        "      --output_file_prefix=$output_folder \\\n",
        "      --num_shards=10 \\\n",
        "      --include_masks=True \\\n",
        "      --num_processes=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "circularNetClean",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
